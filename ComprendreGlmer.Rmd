#Notebook pour comprendre Glmer

```{r}
library(tidyverse)
library(lme4)
library(broom)
library(broom.mixed)
library(patchwork)
```

```{r}
data("sleepstudy")
```
le graphe suivant n'est pas bon, car on considère que toutes les observations sont indépendantes entre elles, alors que pour un même un subject, les obs sont corrélées, mais faut se faire une idée. 
```{r}
library(ggplot2)
ggplot(sleepstudy, aes(x = Days, y = Reaction)) +
  geom_point() +
  geom_smooth(method = "lm")
```
Moins on dort, plus on a un tdr élevé, logique.
```{r}
lme_sleep1 <- lmer(Reaction ~ Days + (1|Subject), data = sleepstudy)
summary(lme_sleep1)
```
On va plot les résultats pour chaque patient
```{r}
lm_sleep <- lm(Reaction ~ Days, data = sleepstudy)

# set up our basic plot
ggplot(sleepstudy, aes(x = Days, y = Reaction)) +
  
  # create separate plots for each subject in the sample
  # and add the data points
  facet_wrap(facets = vars(Subject), nrow = 3) +
  geom_point() +
  
  # this adds the line of best fit for the whole sample
  # (without the random effect), using coefficients
  # from our simple linear model object
  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + 
  
  # and finally, this will add different lines of best fit
  # for each subject as calculated in our mixed model object
  geom_line(data = augment(lme_sleep1), aes(y = .fitted), colour = "blue")
```
On voit qu'on a des soucis pour certains patients, par ex 371 ou le manque de sommeil met plus de temps à affecter son tdr.
  On ajoute cette fois une random slope pour palier à ça, à priori ici c'est pertinent.
```{r}
lme_sleep2 <- lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy)

summary(lme_sleep2)
```
```{r}
ggplot(sleepstudy, aes(x = Days, y = Reaction)) +
  facet_wrap(facets = vars(Subject), nrow = 3) +
  geom_point() +
  
  # the global line of best fit
  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + 
  
  # our previous lines of best fit, with random intercepts
  # but constant slope
  geom_line(data = augment(lme_sleep1), aes(y = .fitted), colour = "blue") +
  
  # our lines of best with random intercepts and random slopes
  geom_line(data = augment(lme_sleep2), aes(y = .fitted), colour = "red") 
```
On voit que le modèle est plus accurate (lignes rouges).

```{r}
ggplot(sleepstudy, aes(x = Days, y = Reaction)) +
  facet_wrap(facets = vars(Subject), nrow = 3) +
  geom_point() +
  
  # the global line of best fit
  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + 
  
  # random intercepts only
  geom_line(data = augment(lme_sleep1), aes(y = .fitted), colour = "blue") +
  
  # random intercepts and random slopes
  geom_line(data = augment(lme_sleep2), aes(y = .fitted), colour = "red") +
  
  # individual regression lines for each individual
  geom_smooth(method = "lm", se = FALSE, colour = "green", linewidth = 0.5)
```
Ici on met en évidence le shrinkage d'information avec un random effect. Pour cela on compare les droites vertes et rouges. Le vert correspond à un RL sur chaque subject indépendamment (no pooling) tandis que le rouge (partial pooling) correspond à notre mixed effects RL. On voit que les droites rouges se rapprochent plus des droites noires: la droite globale tracée au début (complete pooling).

Désormais, on cherche à comprendre la significativité du modèle.

```{r}

lm_null <- lm(Reaction ~ 1, data = sleepstudy)
anova(lme_sleep2, lm_null)
```
On voit que notre modèle est plus performant que le modèle null

#Exo sur les dragons 5

```{r}
data("dragons")
```

```{r}
head(dragons)
```
```{r}
library(tidyr)

dragons_clean <- dragons |>
  separate(
    col = dragon.wingspan.scales.intelligence.mountain,
    into = c("id", "wingspan", "scales", "intelligence", "mountain"),
    sep = ","
  )
dragons_clean$wingspan <- as.numeric(dragons_clean$wingspan)
dragons_clean$intelligence <- as.numeric(dragons_clean$intelligence)
dragons_clean$scales_num <- ifelse(dragons_clean$scales == "chromatic", 1, 0)
ggplot(dragons_clean, aes(y = intelligence, x = wingspan,color=mountain)) +
  geom_point() 

```
On voit qu'un régréssion linéaire fera en effet sûrement le travail pour prédire wingspan avec intelligence et les écailles de dragon.

```{r}
lm_drag <- lmer(intelligence ~ wingspan*scales + (1 +wingspan |mountain), data = dragons_clean)

summary(lm_drag)
```
```{r}
ggplot(augment(lm_drag), aes(x = wingspan, y = intelligence, colour = scales)) +
  facet_wrap(vars(mountain)) +
  geom_point() +
  geom_line(aes(y = .fitted))
```
```{r}
lm_drag2 <- lmer(intelligence ~ wingspan:scales + (1 +wingspan |mountain), data = dragons_clean)

summary(lm_drag2)
```
Ce qui est intéréssant de voir c'est que le modèle converge pas si on enlève l'intéraction wingspan:scale. ça veut dire que à priori les écailles changent vraiment la donne et wingspan a une pente différente en fonction de si c'est chromatic ou metallic.

#exercice 6.6

```{r}
lm_null1 <- lm(intelligence ~ 1, data = dragons_clean)
anova(lm_drag, lm_null1)
```
```{r}
lme_dragons_dropx <- lmer(intelligence ~ wingspan + scales + (1 + wingspan|mountain), 
                          data = dragons_clean)

anova(lm_drag, lme_dragons_dropx)
```
Dans le corrigé, il est écrit que le modèle converge et qu'on voit que wingspan:scale a aucun impact, mais bon chez moi il ne converge pas...

